# -*- coding: utf-8 -*-
"""NLP_project_ML_classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18Q7QWUFXo60yTXueigEhD-E_mUENBjEg
"""

#importing the libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
# For handling string
import string
import spacy
# For visualizations
import matplotlib.pyplot as plt

nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])
from spacy.lang.en.stop_words import STOP_WORDS
from string import punctuation
stopwords = list(STOP_WORDS)

from heapq import nlargest
punctuation = punctuation + '\n'

"""#loading the dataset"""

#reading the data
df = pd.read_csv('/content/Symptom2Disease.csv')

df.head()

df.shape

#removing the unnecessary column
df.drop(['Unnamed: 0'],axis=1, inplace=True)
df.head()

df.shape

#checking if there is any null data
df.info()

original_text = []
for index, row in df.iterrows():
    original_text.append(row['text'])

df = df.assign(Original_text = original_text)

df.head()

df.nunique()

df = df.drop_duplicates()
df.info()

"""#Preprocessing the text data"""

# Dictionary of English Contractions
contractions_dict = { "ain't": "are not","'s":" is","aren't": "are not",
                     "can't": "cannot","can't've": "cannot have",
                     "'cause": "because","could've": "could have","couldn't": "could not",
                     "couldn't've": "could not have", "didn't": "did not","doesn't": "does not",
                     "don't": "do not","hadn't": "had not","hadn't've": "had not have",
                     "hasn't": "has not","haven't": "have not","he'd": "he would",
                     "he'd've": "he would have","he'll": "he will", "he'll've": "he will have",
                     "how'd": "how did","how'd'y": "how do you","how'll": "how will",
                     "I'd": "I would", "I'd've": "I would have","I'll": "I will",
                     "I'll've": "I will have","I'm": "I am","I've": "I have", "isn't": "is not",
                     "it'd": "it would","it'd've": "it would have","it'll": "it will",
                     "it'll've": "it will have", "let's": "let us","ma'am": "madam",
                     "mayn't": "may not","might've": "might have","mightn't": "might not",
                     "mightn't've": "might not have","must've": "must have","mustn't": "must not",
                     "mustn't've": "must not have", "needn't": "need not",
                     "needn't've": "need not have","o'clock": "of the clock","oughtn't": "ought not",
                     "oughtn't've": "ought not have","shan't": "shall not","sha'n't": "shall not",
                     "shan't've": "shall not have","she'd": "she would","she'd've": "she would have",
                     "she'll": "she will", "she'll've": "she will have","should've": "should have",
                     "shouldn't": "should not", "shouldn't've": "should not have","so've": "so have",
                     "that'd": "that would","that'd've": "that would have", "there'd": "there would",
                     "there'd've": "there would have", "they'd": "they would",
                     "they'd've": "they would have","they'll": "they will",
                     "they'll've": "they will have", "they're": "they are","they've": "they have",
                     "to've": "to have","wasn't": "was not","we'd": "we would",
                     "we'd've": "we would have","we'll": "we will","we'll've": "we will have",
                     "we're": "we are","we've": "we have", "weren't": "were not","what'll": "what will",
                     "what'll've": "what will have","what're": "what are", "what've": "what have",
                     "when've": "when have","where'd": "where did", "where've": "where have",
                     "who'll": "who will","who'll've": "who will have","who've": "who have",
                     "why've": "why have","will've": "will have","won't": "will not",
                     "won't've": "will not have", "would've": "would have","wouldn't": "would not",
                     "wouldn't've": "would not have","y'all": "you all", "y'all'd": "you all would",
                     "y'all'd've": "you all would have","y'all're": "you all are",
                     "y'all've": "you all have", "you'd": "you would","you'd've": "you would have",
                     "you'll": "you will","you'll've": "you will have", "you're": "you are",
                     "you've": "you have"}

# Regular expression for finding contractions
contractions_re=re.compile('(%s)' % '|'.join(contractions_dict.keys()))

# Function for expanding contractions
def expand_contractions(text,contractions_dict=contractions_dict):
  def replace(match):
    return contractions_dict[match.group(0)]
  return contractions_re.sub(replace, text)

# Expanding Contractions in the reviews
df['text']=df['text'].apply(lambda x:expand_contractions(x))

# change all text to lower case
df['text']=df['text'].apply(lambda x: x.lower())

# remove punctuations
df['text']=df['text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))

# Lemmatization with stopwords removal
df['text']=df['text'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))

df.head()

#categorical encoding of labels
from sklearn.preprocessing import LabelEncoder
lb = LabelEncoder()
df["label_no"]=lb.fit_transform(df["label"])
df.head()

"""#Train test Splitting"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

X_train, X_test, y_train, y_test = train_test_split(df["text"], df["label_no"], test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=1500)

X_train_v = vectorizer.fit_transform(X_train).toarray()
X_test_v = vectorizer.transform(X_test).toarray()

"""# Using Decision Tree Claasifier"""

#creating model for the classification
from sklearn.tree import DecisionTreeClassifier
dtc = DecisionTreeClassifier(criterion='gini', max_depth=24, random_state=0)
dtc.fit(X_train_v, y_train)

y_pred = dtc.predict(X_test_v)

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import confusion_matrix
import seaborn as sns
# %matplotlib inline

def report(y_test,y_pred):
    accuracy = accuracy_score(y_test, y_pred)
    print(f'Accuracy: {accuracy:.2f}')
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)

    plt.subplots(figsize=(12,12))
    ax = plt.subplot()
    sns.heatmap(cm, annot=True, ax=ax)  #annot=True to annotate cells

    # labels, title and ticks
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title('Confusion Matrix')

report(y_test,y_pred)

# getting prediction on random text
# modification has been done on the original text and getting the prediction after modification
sent1 = 'These fractures hurt and bleed frequently. The fractures are itchy and covered with scales. My fingers and soles have pretty thick skin that is cracked severely' # Psoriasis
sent2 = 'I am feeling sick. I have a fever and headache. I noticed rashes on my arms and face. I am worried about this. I observed red sores near my nose.' # Impetigo
sent3 = 'I have a rash on my legs that is causing discomforts. There is a cramp and I can see prominent veins on the calf. I have been feeling very tired and fatigued in the past couple of days.' # Varicose Veins

text = [sent1, sent2, sent3]

#preprocessign the text before testing
# Expanding Contractions in the reviews
text = list(map(lambda x: expand_contractions(x), text))

# change all text to lower case
text = list(map(lambda x: x.lower(), text))

# remove punctuations
text = list(map(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x), text))

# Lemmatization with stopwords removal
text = list(map(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]), text))

newtest_v = vectorizer.transform(text).toarray()

y_pred = dtc.predict(newtest_v)


print(y_pred)
print(lb.inverse_transform(y_pred))

"""# Using SVM model"""

from sklearn.svm import SVC
svm = SVC(kernel = 'linear', C = 1).fit(X_train_v, y_train)
svm_pred = svm.predict(X_test_v)

report(y_test,svm_pred)

# getting prediction on random text
# modification has been done on the original text and getting the prediction after modification
sent1 = 'These fractures hurt and bleed frequently. The fractures are itchy and covered with scales. My fingers and soles have pretty thick skin that is cracked severely' # Psoriasis
sent2 = 'I am feeling sick. I have a fever and headache. I noticed rashes on my arms and face. I am worried about this. I observed red sores near my nose.' # Impetigo
sent3 = 'I have a rash on my legs that is causing discomforts. There is a cramp and I can see prominent veins on the calf. I have been feeling very tired and fatigued in the past couple of days.' # Varicose Veins

text = [sent1, sent2, sent3]

#preprocessign the text before testing
# Expanding Contractions in the reviews
text = list(map(lambda x: expand_contractions(x), text))

# change all text to lower case
text = list(map(lambda x: x.lower(), text))

# remove punctuations
text = list(map(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x), text))

# Lemmatization with stopwords removal
text = list(map(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]), text))

newtest_v = vectorizer.transform(text).toarray()

y_pred = svm.predict(newtest_v)


print(y_pred)
print(lb.inverse_transform(y_pred))

"""# Use of summarized text as test data and predicting the result"""

# Here we upload the summarized data which we get from summarization in another file (from fine tuning file)
newDf = pd.read_csv('/content/summary.csv')

newDf.head()

newDf.info()

newDf.drop(['Unnamed: 0'],axis=1, inplace=True)
newDf.head()

newDf["summary_original"] = newDf["summary_original"].apply(lambda x: str(x))

# Expanding Contractions in the reviews
newDf['summary_original']=newDf['summary_original'].apply(lambda x:expand_contractions(x))

# change all text to lower case
newDf['summary_original']=newDf['summary_original'].apply(lambda x: x.lower())

# remove punctuations
newDf['summary_original']=newDf['summary_original'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))

# Lemmatization with stopwords removal
newDf['summary_original']=newDf['summary_original'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))

newDf.head()

newDf.info()

# actual values
print ("Actual values")
print (f"{newDf.iloc[1]['label']}, {newDf.iloc[10]['label']}, {newDf.iloc[75]['label']}, {newDf.iloc[11]['label']}, {newDf.iloc[49]['label']}, {newDf.iloc[105]['label']}")

print ("Predicted values")
text = [newDf.iloc[1]['summary_original'], newDf.iloc[10]['summary_original'], newDf.iloc[75]['summary_original'], newDf.iloc[11]['summary_original'], newDf.iloc[49]['summary_original'], newDf.iloc[105]['summary_original']]

newtest_v = vectorizer.transform(text).toarray()


#using decision tree classifier model to predict
y_pred = dtc.predict(newtest_v)


print(y_pred)
print(lb.inverse_transform(y_pred))

#predicting for all the summarized text through decision tree model

test_summarized_v = vectorizer.transform(newDf['summary_original']).toarray()

y_pred_dtc = dtc.predict(test_summarized_v)
print(y_pred_dtc)

y_test_dtc= newDf['label_int'].tolist()

report(y_test_dtc,y_pred_dtc)

"""Using SVM model for prediction of summarirized text"""

y_pred_svm = svm.predict(test_summarized_v)
print(y_pred_svm)

y_test_svm= newDf['label_int'].tolist()

report(y_test_svm,y_pred_svm)